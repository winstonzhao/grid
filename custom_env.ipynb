{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd69d3-8b6e-4637-a633-83fa4c657f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from random import randrange\n",
    "\n",
    "SIZE = 10\n",
    "REWARD_COUNT = 1\n",
    "MAX_STEPS = 2500\n",
    "\n",
    "class PathFindingEnvironment(gym.Env):\n",
    "    \"\"\"Simple Pathfinding Environment\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PathFindingEnvironment, self).__init__()\n",
    "        self.reward_range = (0, 1)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.MultiDiscrete([3] * SIZE * SIZE)\n",
    "        self.num_rounds = 0\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        old_player_location = [self.player_location[0], self.player_location[1]]\n",
    "        if action == 0:\n",
    "            self.player_location[0] = min(self.player_location[0] + 1, SIZE - 1)\n",
    "        elif action == 1:\n",
    "            self.player_location[0] = max(self.player_location[0] - 1, 0)\n",
    "        elif action == 2:\n",
    "            self.player_location[1] = min(self.player_location[1] + 1, SIZE - 1)\n",
    "        elif action == 3:\n",
    "            self.player_location[1] = max(self.player_location[1] - 1, 0)\n",
    "        \n",
    "        done = False\n",
    "        reward = 0\n",
    "                \n",
    "        if self.map[self.player_location[0]][self.player_location[1]] == 1:\n",
    "            reward = 1 - min(self.num_steps / MAX_STEPS, 0.9)\n",
    "            self.reward_count -= 1\n",
    "            if self.reward_count == 0:\n",
    "                done = True\n",
    "        \n",
    "        if self.num_steps == MAX_STEPS:\n",
    "            done = True\n",
    "        \n",
    "     \n",
    "        self.map[old_player_location[0]][old_player_location[1]] = 0\n",
    "        self.map[self.player_location[0]][self.player_location[1]] = 2\n",
    "        \n",
    "        self.num_steps += 1\n",
    "        return self.get_obs(), reward, done, {}\n",
    "    \n",
    "    def get_obs(self):\n",
    "        out = []\n",
    "        for row in self.map:\n",
    "            for col in row:\n",
    "                out.append(col)\n",
    "        return np.array(out)\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.map = [[0 for j in range(SIZE)] for i in range(SIZE)]\n",
    "        for i in range(REWARD_COUNT):\n",
    "            reward_location = [randrange(SIZE), randrange(SIZE)]\n",
    "            while (self.map[reward_location[0]][reward_location[1]] == 1):\n",
    "                reward_location = [randrange(SIZE), randrange(SIZE)]\n",
    "            self.map[reward_location[0]][reward_location[1]] = 1\n",
    "        self.reward_count = REWARD_COUNT\n",
    "        self.num_rounds += 1\n",
    "        self.num_steps = 0\n",
    "        self.player_location = [randrange(SIZE), randrange(SIZE)]\n",
    "        while (self.map[self.player_location[0]][self.player_location[1]] == 1):\n",
    "             self.player_location = [randrange(SIZE), randrange(SIZE)]\n",
    "        self.map[self.player_location[0]][self.player_location[1]] = 2\n",
    "        return self.get_obs()\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen    \n",
    "        for row in self.map:\n",
    "            display = \"\"\n",
    "            for col in row:\n",
    "                if col == 0:\n",
    "                    display += ' '\n",
    "                elif col == 1:\n",
    "                    display += '*'\n",
    "                elif col == 2:\n",
    "                    display += 'X'\n",
    "            print(display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39115333-c77a-4c81-8db8-a7fd7c3e93e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67376/3652949078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vec_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPathFindingEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCnnPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./tensorboard/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/stable_baselines/acer/acer_simple.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, gamma, n_steps, num_procs, q_coef, ent_coef, max_grad_norm, learning_rate, lr_schedule, rprop_alpha, rprop_epsilon, buffer_size, replay_ratio, replay_start, correction_term, trust_region, alpha, delta, verbose, tensorboard_log, _init_setup_model, policy_kwargs, full_tensorboard_log, seed, n_cpu_tf_sess)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAbstractEnvRunner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/stable_baselines/acer/acer_simple.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mn_batch_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_envs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 step_model = self.policy(self.sess, self.observation_space, self.action_space, self.n_envs, 1,\n\u001b[0m\u001b[1;32m    285\u001b[0m                                          n_batch_step, reuse=False, **self.policy_kwargs)\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/stable_baselines/common/policies.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, ob_space, ac_space, n_env, n_steps, n_batch, reuse, **_kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mob_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         super(CnnPolicy, self).__init__(sess, ob_space, ac_space, n_env, n_steps, n_batch, reuse,\n\u001b[0m\u001b[1;32m    701\u001b[0m                                         feature_extraction=\"cnn\", **_kwargs)\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/stable_baselines/common/policies.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, ob_space, ac_space, n_env, n_steps, n_batch, reuse, layers, net_arch, act_fun, cnn_extractor, feature_extraction, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeature_extraction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cnn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                 \u001b[0mpi_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvf_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfeature_extraction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid_mlp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0mprocessed_p1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_p2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/stable_baselines/common/policies.py\u001b[0m in \u001b[0;36mnature_cnn\u001b[0;34m(scaled_images, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m     \u001b[0mactiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mlayer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlayer_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/stable_baselines/common/tf_layers.py\u001b[0m in \u001b[0;36mconv\u001b[0;34m(input_tensor, scope, n_filters, filter_size, stride, pad, init_scale, data_format, one_dim_bias)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mbias_var_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mone_dim_bias\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_ax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mwshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilter_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    894\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy, MlpLnLstmPolicy, FeedForwardPolicy, CnnPolicy\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines import PPO2, DQN, ACER\n",
    "from IPython.display import display, clear_output\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# The algorithms require a vectorized environment to run\n",
    "\n",
    "# # Custom MLP policy of three layers of size 128 each\n",
    "# class CustomPolicy(FeedForwardPolicy):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super(CustomPolicy, self).__init__(*args, **kwargs,\n",
    "#                                            net_arch=[dict(pi=[64, 64, 64, 64, 64, 64],\n",
    "#                                                           vf=[64, 64, 64, 64, 64, 64])],\n",
    "#                                            feature_extraction=\"mlp\")\n",
    "\n",
    "env = make_vec_env(PathFindingEnvironment, n_envs=8)\n",
    "model = ACER(CnnPolicy, env, tensorboard_log=\"./tensorboard/\")\n",
    "model.setup_model()\n",
    "model.learn(total_timesteps=2000000)\n",
    "env.get_attr('num_rounds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca1f1b3-76b1-47ec-bcfd-8857d1072a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "      \n",
      "      \n",
      "      \n",
      " X    \n",
      "*     \n",
      "      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37677/29014633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "\n",
    "# # Evaluate the agent\n",
    "# mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=1000)\n",
    "done = 0\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "#     action=[randrange(4)]\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    if (dones[0]):\n",
    "        done += 1\n",
    "        print(rewards)\n",
    "        print(i)\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "    env.envs[0].render()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd1b1d-a5de-47c9-b4e3-d6a47a007215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
